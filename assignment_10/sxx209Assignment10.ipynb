{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligent Systems 2022: 10th  Practical Assignment\n",
    "## Machine Learning Introduction\n",
    "\n",
    "Your name: Sebastião Manuel Inácio Rosalino\n",
    "\n",
    "Your VUnetID: sxx209\n",
    "\n",
    "If you do not provide your name and VUnetID we will not accept your submission. \n",
    "\n",
    "### Preliminaries\n",
    "\n",
    "At the end of this exercise you should be able to work with some basic Machine Learning concepts, and implement and evaluate simple classifiers for *spam classification* using the popular machine learning library scikit-learn(https://scikit-learn.org/stable/).\n",
    "Scikit-learn offers a many helpful methods for creating simple machine learning models and to perform data science.\n",
    "\n",
    "In this assignment you will:\n",
    "1. Use pandas to read a dataset from a comma-separated-value (.csv) file.\n",
    "2. You should be able to create tf-idf feature vectors with scikit-learn.\n",
    "3. You should be able to create a simple classification and evaluate basic classification models.\n",
    "4. You should have learned to improve classification models for textual data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Practicalities\n",
    "\n",
    "Follow this Notebook step-by-step. For this course it is necessary that you manipulate the python programmes we provide. You can do the exercises in any Programming Editor of your liking. Still, please fill in the questions in this notebook as usual. \n",
    "\n",
    "Please use your studentID+Assignment10.ipynb as the name of the Notebook, and fill in the missing cells.   \n",
    "\n",
    "Note: unlike the courses dedicated to programming we will not evaluate the style of the programs. But we will, however, test your programs on other data that we provide, and your program should give the correct output to the test-data as well.\n",
    "\n",
    "As was mentioned, the assignment is graded as pass/fail. To pass you need to have either a full working code or an explanation of what you tried and what didn't work for the tasks that you were unable to complete (you can use multi-line comments or a text cell).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install some packages\n",
    "\n",
    "First we need to install some additional packages that we will use throughout this assignment.\n",
    "This might take a while.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\sebas\\anaconda3\\envs\\main_env\\lib\\site-packages (1.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\sebas\\anaconda3\\envs\\main_env\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\sebas\\anaconda3\\envs\\main_env\\lib\\site-packages (from pandas) (1.22.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sebas\\anaconda3\\envs\\main_env\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sebas\\anaconda3\\envs\\main_env\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sebas\\anaconda3\\envs\\main_env\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\sebas\\anaconda3\\envs\\main_env\\lib\\site-packages (from scikit-learn) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\sebas\\anaconda3\\envs\\main_env\\lib\\site-packages (from scikit-learn) (1.22.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sebas\\anaconda3\\envs\\main_env\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\sebas\\anaconda3\\envs\\main_env\\lib\\site-packages (from scikit-learn) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training classification models with Sci-Kit Learn.\n",
    "\n",
    "With this notebbook, you have downloaded a small .csv file containing a public spam/ham SMS dataset that is often used for text classification purposes.\n",
    "We will load this dataset with the pandas library (https://pandas.pydata.org/), which is often used for data analysis.\n",
    "\n",
    "#### Note that you might re-run the Notebook multiple times, because the *df* variable is overwritten multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "import pandas as pd\n",
    "df = pd.read_csv ('spam.csv', encoding=\"latin-1\")\n",
    "df.dropna(how=\"any\", inplace=True, axis=1)\n",
    "df.columns = ['label', 'message']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the resulting pandas dataframe contains an index column, a label, and the message.\n",
    "Let's first have a look at the class distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "For this first task, we ask you to do a basic data science task. Try to get an idea about the dataset by checking how balanced/unbalanced the dataset is. To do this, you need to compute the proportion of the *ham* and the *spam* class.\n",
    "\n",
    "Find a Pandas function to compute the frequency of the labels to get an idea of the label distribution. \n",
    "Then write a short description of your results.\n",
    "What percentage of the messages are labelled as spam?\n",
    "\n",
    "*Hint: Have a look at the Pandas documentation (https://pandas.pydata.org/docs/). There a many ways to get your answer!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.593683\n",
       "spam    13.406317\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write your Code for task 1 here.\n",
    "\n",
    "(df['label'].value_counts() / len(df)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyReport1 = \"\"\"\n",
    "\n",
    "To calculate the proportion of the label classes (ham and spam) on the dataset, I used the pandas function \"value_counts\" to count how many times in\n",
    "total each label occured, divided by the total number of instances in the dataset, and that result multiplied by 100, so that I could get the relative\n",
    "frequency of each label in percentage format.\n",
    "When it comes to the results, approximately 86.6% were labelled as ham and approximately 13.4% were labelled as spam.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snipped will create textual features, as discussed in last weeks lecture. We will create tf-idf vectors and will append them to our pandas dataframe.\n",
    "Then we will perform a simple train/test split of our dataset, using the scikit-learn splitting functions.\n",
    "\n",
    "Have a look at the different parts that we created. What do the dataframes X_train, y_train, X_test, y_test contain?\n",
    "Try to understand what is happening here by also having a look at the scikit-learn documentation (https://scikit-learn.org/stable/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sebas\\anaconda3\\envs\\main_env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#compute the tf-idf vectors for the messages and create a new dataframe for them\n",
    "v = TfidfVectorizer()\n",
    "tf_idf = v.fit_transform(df['message'])\n",
    "df_tfidf = pd.DataFrame(tf_idf.toarray(), columns=v.get_feature_names())\n",
    "\n",
    "#combine the original dataframe with the dataframe for the tf-idf vectors\n",
    "dataframes = [df, df_tfidf]\n",
    "df_new = pd.concat(dataframes, axis=1)\n",
    "\n",
    "#split the dataset into training and test set\n",
    "train, test = train_test_split(df_new, test_size=0.9)\n",
    "\n",
    "#separate feature matrices X from label vector y\n",
    "X_train = train.iloc[:, 3:]\n",
    "X_test = test.iloc[:, 3:]\n",
    "y_train = train['label']\n",
    "y_test = test['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>0207</th>\n",
       "      <th>...</th>\n",
       "      <th>ó_</th>\n",
       "      <th>û_</th>\n",
       "      <th>û_thanks</th>\n",
       "      <th>ûªm</th>\n",
       "      <th>ûªt</th>\n",
       "      <th>ûªve</th>\n",
       "      <th>ûï</th>\n",
       "      <th>ûïharry</th>\n",
       "      <th>ûò</th>\n",
       "      <th>ûówell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3954</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5558</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4671</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>557 rows × 8671 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      000  000pes  008704050406  0089  0121  01223585236  01223585334  \\\n",
       "807   0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "168   0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "723   0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "4175  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "3954  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "...   ...     ...           ...   ...   ...          ...          ...   \n",
       "5558  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "1820  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "3199  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "4671  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "1872  0.0     0.0           0.0   0.0   0.0          0.0          0.0   \n",
       "\n",
       "      0125698789   02  0207  ...   ó_   û_  û_thanks  ûªm  ûªt  ûªve   ûï  \\\n",
       "807          0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "168          0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "723          0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "4175         0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "3954         0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "...          ...  ...   ...  ...  ...  ...       ...  ...  ...   ...  ...   \n",
       "5558         0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "1820         0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "3199         0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "4671         0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "1872         0.0  0.0   0.0  ...  0.0  0.0       0.0  0.0  0.0   0.0  0.0   \n",
       "\n",
       "      ûïharry   ûò  ûówell  \n",
       "807       0.0  0.0     0.0  \n",
       "168       0.0  0.0     0.0  \n",
       "723       0.0  0.0     0.0  \n",
       "4175      0.0  0.0     0.0  \n",
       "3954      0.0  0.0     0.0  \n",
       "...       ...  ...     ...  \n",
       "5558      0.0  0.0     0.0  \n",
       "1820      0.0  0.0     0.0  \n",
       "3199      0.0  0.0     0.0  \n",
       "4671      0.0  0.0     0.0  \n",
       "1872      0.0  0.0     0.0  \n",
       "\n",
       "[557 rows x 8671 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's have a look at the different dataframes here\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classification\n",
    "\n",
    "\n",
    "In the lecture, we have introduced the naive Bayes classification algorithm and have already computed various examples by hand. Here, we will use scikit-learn to train your first own classification model for spam classification.\n",
    "However, all examples from the lecture were using categorical features, while our tf-idf vectors here are real-valued features. \n",
    "Thus, the model used here will be slightly different than what we have seen in the lecture.\n",
    "\n",
    "\n",
    "\n",
    "### Task 2\n",
    "\n",
    "Use the training and test set created in the previous cell and train a Naive Bayes classifier using sci-kit learn.\n",
    "Please have a look at the documentation on how to use classification model using X_train and y_train as an input.\n",
    "Afterwards compute the accuracy of your classfier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of my Naive Bayes classifier was: 0.8685942173479562\n"
     ]
    }
   ],
   "source": [
    "# My classification code\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "y_test_prediction_naive_bayes = MultinomialNB().fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "# Computing the accuracy of my Naive Bayes classifier\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"The accuracy of my Naive Bayes classifier was:\", metrics.accuracy_score(y_test, y_test_prediction_naive_bayes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might have seen, the accuracy of your Naive Bayes classifier should be over 95%.\n",
    "This seems to be a very good score, for a very simple classification model and simple tf-idf features.\n",
    "\n",
    "### Task 3\n",
    "\n",
    "Have a look at different evaluation metrics for your classifier and discuss the suitability of accuracy for the spam classification task.\n",
    "Have a look at the definition of accuracy and come up with another metric, which is better suited for our problem\n",
    "\n",
    "*Hint: Have a look at this documentation and try out different evaluation metrics: https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The balanced accuracy of my Naive Bayes classifier was: 0.5118518518518519\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Computing the balanced accuracy of my Naive Bayes classifier\n",
    "\n",
    "print(\"The balanced accuracy of my Naive Bayes classifier was:\", metrics.balanced_accuracy_score(y_test, y_test_prediction_naive_bayes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyReport2 = \"\"\"\n",
    "\n",
    "The accuracy evaluation metric has showed manifestly high results. It is important to remember that accuracy is calculated as the percentage of correct \n",
    "predictions of the model in relation to the target class effectively assumed in each instance of the test set. However, this evaluation metric will not \n",
    "be the most appropriate for the dataset under study, because, as described in the documentation, this metric was designed to act on multiclass \n",
    "classification problems.\n",
    "\n",
    "In order to obtain a more adequate and realistic perspective of the performance that our model presented with respect to the given dataset, I found the \n",
    "balanced accuracy evaluation metric. This evaluation metric best suits the characteristics of the dataset because, as described in the documentation, \n",
    "this metric was designed to deal not only with multiclass classification problems, but also with binary classification problems, as it is our goal to \n",
    "predict whether a message it's spam or ham. In addition, this metric appears to be more weighted and balanced in relation to the target class of the \n",
    "dataset, since calculating accuracy in the same way as the accuracy metric, it now takes into account the frequency and proportion that each label is \n",
    "represented.\n",
    "\n",
    "As is clear from the output obtained, the evaluation of the model's predictive capacity upon the test set according to this new metric was much worse.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "Come up with any improvements for the classification model here.\n",
    "You can come up with a new method and/or different features to improve the classification.\n",
    "Can you beat the baseline Naive Bayes model?\n",
    "\n",
    "If you try out a different classification model, the training of the model might take a couple of seconds.\n",
    "\n",
    "Write at least 10 sentences describing your improvements and why these improvements are helping to improve the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The balanced accuracy of my Decision Tree classifier was: 0.862652329749104\n"
     ]
    }
   ],
   "source": [
    "# My first experiment will be to perform a classifier model based on a Classification Decision Tree\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "y_test_prediction_decision_tree = tree.DecisionTreeClassifier().fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "# Computing the balanced accuracy of my Classification Decision Tree model\n",
    "\n",
    "print(\"The balanced accuracy of my Decision Tree classifier was:\", metrics.balanced_accuracy_score(y_test, y_test_prediction_decision_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The balanced accuracy of my KNN classifier was: 0.852231609489674\n"
     ]
    }
   ],
   "source": [
    "# My second experiment will be to perform a classifier model based KNN (K-Nearest Neighbour)\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "my_knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "my_knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_test_prediction_knn = my_knn_classifier.predict(X_test)\n",
    "\n",
    "# Computing the balanced accuracy of my KNN Classification model\n",
    "\n",
    "print(\"The balanced accuracy of my KNN classifier was:\", metrics.balanced_accuracy_score(y_test, y_test_prediction_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyReport3 = \"\"\"\n",
    "\n",
    "In order to improve the model's ability to classify SMS in spam/ham, I carried out two experiments.\n",
    "\n",
    "The first one consisted of using a different classification model, the Classification Decision Tree. After fitting this model on the training set and \n",
    "predicting the labels on the test set, this model presented a much better result, according to the balanced accuracy metric, than the Naive Bayes \n",
    "classifier used in task 3. Therefore, beating the baseline Naive Bayes model.\n",
    "\n",
    "Moving on to the second experiment, this consisted of using another different model, the KNN (K-Nearest Neighbour). After fitting this model on the \n",
    "training set and predicting the labels on the test set, this classifier presented a much better result, according to the balanced accuracy metric, than \n",
    "the Naive Bayes classifier used in task 3. Thus, beating once again the baseline Naive Bayes model. Noteworthy to mention that this model was executed by \n",
    "setting K=3, which means that this model performed its spam/ham classifications in each message based on the 3 messages that were most \"close\" and \n",
    "\"similar\" in terms of their features of the message in question. Finally, this model presented results, according to the balanced accuracy metric, very \n",
    "similar to those obtained in the model that used the Decision Tree classifier.\n",
    "\n",
    "To sum up, these two approaches, based on different models, are greatly improving the predictive capacity, due to the fact that the Naive \n",
    "Bayes baseline is not a robust enough model, and therefore, too simplistic, to deal with the characteristics of the dataset in order to present a good \n",
    "prediction upon the labels on the test set, whereas both the Decision Tree classifier and the KNN classifier constitute more \"educated\" and complex\n",
    "models due to the procedures adopted in their classifying process of messages in spam/ham.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Task: Collect all the results\n",
    "\n",
    "Uncomment and run this cell (and all the cells above) to generate the text file that you have to hand in together with the notebook on canvas!\n",
    "\n",
    "### Please hand in only the text file which is generated by this method!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "exportToText(\"assignment10.txt\", MyReport1, MyReport2, MyReport3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "08d7406bcc4c8ede7e3b7d9b78083bc28f6be7dbc1b543b9edaca5da1bd54874"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
